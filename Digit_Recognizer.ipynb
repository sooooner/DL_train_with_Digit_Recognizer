{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [DIGIT Recognizer](https://www.kaggle.com/c/digit-recognizer)\n",
    "<img src=\"images/front_page.png\" style=\"width:350px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load & Pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "41995       0    ...            0         0         0         0         0   \n",
       "41996       0    ...            0         0         0         0         0   \n",
       "41997       0    ...            0         0         0         0         0   \n",
       "41998       0    ...            0         0         0         0         0   \n",
       "41999       0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "27995       0       0       0       0       0       0       0       0       0   \n",
       "27996       0       0       0       0       0       0       0       0       0   \n",
       "27997       0       0       0       0       0       0       0       0       0   \n",
       "27998       0       0       0       0       0       0       0       0       0   \n",
       "27999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "27995       0    ...            0         0         0         0         0   \n",
       "27996       0    ...            0         0         0         0         0   \n",
       "27997       0    ...            0         0         0         0         0   \n",
       "27998       0    ...            0         0         0         0         0   \n",
       "27999       0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "27995         0         0         0         0         0  \n",
       "27996         0         0         0         0         0  \n",
       "27997         0         0         0         0         0  \n",
       "27998         0         0         0         0         0  \n",
       "27999         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY = df_train[\"label\"]\n",
    "dfY = pd.get_dummies(dfY)\n",
    "dfY = dfY.as_matrix().reshape(len(dfY), -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = df_train.drop(\"label\", axis = 1)\n",
    "dfX /= np.max(np.max(dfX))\n",
    "dfX = dfX.as_matrix().reshape(len(dfX), -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test /= np.max(np.max(df_test))\n",
    "df_test = df_test.as_matrix().reshape(len(df_test), -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 42000), (10, 42000), (784, 28000))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfX), np.shape(dfY), np.shape(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAHiCAYAAADxt5d3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ad8835c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "for i in range(12):\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    plt.imshow(dfX[:, i].reshape(28,28))\n",
    "    plt.axis('off')\n",
    "    plt.title(np.where(dfY[:, i] == 1)[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAHVCAYAAADoyKBiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ad88607c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "for i in range(12):\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    plt.imshow(df_test[:, i].reshape(28,28))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4132 4684 4177 4351 4072 3795 4137 4401 4063 4188]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ad88ff2780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(list(range(10)), np.sum(dfY, axis=1), palette='Greens_d')\n",
    "print(np.sum(dfY, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check None Value\n",
    "# assert(dfX.isnull().any().count() == np.shape(dfX)[1])\n",
    "# assert(dfY.isnull().any().count() == np.shape(dfY)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(dfX, dfY):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dfX -- input dataset of shape (input size, number of examples)\n",
    "    dfY -- labels of shape (output size, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    n_x -- the size of the input layer\n",
    "    n_hi -- the size of the hidden layer\n",
    "    n_y -- the size of the output layer\n",
    "    \"\"\"\n",
    "\n",
    "    n_x = dfX.shape[0]      # size of input layer\n",
    "    n_h1 = 128\n",
    "    n_h2 = 128\n",
    "    n_h3 = 128\n",
    "    n_y = dfY.shape[0]      # size of output layer\n",
    "    layer_dims = (n_x, n_h1, n_h2, n_h3, n_y)\n",
    "    \n",
    "    return layer_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 128, 128, 128, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dims = layer_sizes(dfX, dfY)\n",
    "layer_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    layer_dims -- output of layer_sizes()\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h1, n_x)\n",
    "                    b1 -- bias vector of shape (n_h1, 1)\n",
    "                    W2 -- weight matrix of shape (n_h2, n_h1)\n",
    "                    b2 -- bias vector of shape (n_h2, 1)\n",
    "                    W3 -- weight matrix of shape (n_y, n_h2)\n",
    "                    b3 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)   \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.1\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_parameters(layer_dims)\n",
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape W1 : (128, 784)\n",
      "shape b1 : (128, 1)\n",
      "shape W2 : (128, 128)\n",
      "shape b2 : (128, 1)\n",
      "shape W3 : (128, 128)\n",
      "shape b3 : (128, 1)\n",
      "shape W4 : (10, 128)\n",
      "shape b4 : (10, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in parameters.keys():\n",
    "    print(\"shape {} :\".format(i), np.shape(parameters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 42000)\n",
      "Z = [[ -7.77738152e-01  -4.35866678e+00  -9.80310349e-01 ...,  -2.30466824e+00\n",
      "   -2.18948154e+00  -1.64403224e+00]\n",
      " [  2.09005949e+00   8.63554220e-01  -3.32598141e-01 ...,  -2.71707471e-01\n",
      "    6.42573448e-01   4.09528535e-01]\n",
      " [ -6.14081593e-01   4.39410513e-01  -8.24271316e-01 ...,  -8.79024755e-01\n",
      "   -5.63683133e-01  -1.19716513e+00]\n",
      " ..., \n",
      " [ -3.86671274e-01   2.83271352e-01   2.63957027e-01 ...,   3.45443681e-01\n",
      "   -1.93734851e-01  -8.11186681e-02]\n",
      " [ -7.38926893e-03   2.80773043e+00   1.94340708e-01 ...,   3.90852399e-01\n",
      "    9.12904122e-01   4.30378264e-01]\n",
      " [  5.39345447e-01  -1.63787572e+00  -2.72880756e-03 ...,  -7.97527727e-01\n",
      "   -1.20683291e+00  -8.83847535e-01]]\n"
     ]
    }
   ],
   "source": [
    "A, W, b = dfX, parameters['W1'], parameters['b1']\n",
    "Z, linear_cache = linear_forward(A, W, b)\n",
    "print(Z.shape)\n",
    "print(\"Z = \" + str(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31480757,  0.01263378,  0.27283021, ...,  0.09073708,\n",
       "         0.10069904,  0.16191714],\n",
       "       [ 0.88993325,  0.7034027 ,  0.41760859, ...,  0.43248796,\n",
       "         0.65533496,  0.60097483],\n",
       "       [ 0.35112869,  0.60811856,  0.30485773, ...,  0.29337991,\n",
       "         0.36269568,  0.23197991],\n",
       "       ..., \n",
       "       [ 0.40451888,  0.57034806,  0.56560877, ...,  0.58551225,\n",
       "         0.45171721,  0.47973145],\n",
       "       [ 0.49815269,  0.94309214,  0.54843284, ...,  0.59648788,\n",
       "         0.71359407,  0.60596399],\n",
       "       [ 0.63166014,  0.16275432,  0.4993178 , ...,  0.31055461,\n",
       "         0.23026191,  0.29238111]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(Z)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU activation in numpy.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.09005949,  0.86355422,  0.        , ...,  0.        ,\n",
       "         0.64257345,  0.40952854],\n",
       "       [ 0.        ,  0.43941051,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.28327135,  0.26395703, ...,  0.34544368,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  2.80773043,  0.19434071, ...,  0.3908524 ,\n",
       "         0.91290412,  0.43037826],\n",
       "       [ 0.53934545,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(Z)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Implement the softmax activation in numpy.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.68911192e-03,   4.72370679e-05,   2.11265473e-03, ...,\n",
       "          3.74112937e-04,   5.58444405e-04,   1.01407731e-03],\n",
       "       [  4.73235777e-02,   8.75517224e-03,   4.03762857e-03, ...,\n",
       "          2.85697455e-03,   9.48256431e-03,   7.90535137e-03],\n",
       "       [  3.16726221e-03,   5.72877048e-03,   2.46942260e-03, ...,\n",
       "          1.55650968e-03,   2.83827989e-03,   1.58541508e-03],\n",
       "       ..., \n",
       "       [  3.97600632e-03,   4.90062021e-03,   7.33173876e-03, ...,\n",
       "          5.29580167e-03,   4.10886353e-03,   4.83989349e-03],\n",
       "       [  5.80987980e-03,   6.11800313e-02,   6.83869128e-03, ...,\n",
       "          5.54182066e-03,   1.24259304e-02,   8.07190607e-03],\n",
       "       [  1.00371639e-02,   7.17641386e-04,   5.61547885e-03, ...,\n",
       "          1.68867291e-03,   1.49189693e-03,   2.16877794e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(Z)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\" or \"tanh\" or \"softmax\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)  \n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        A, activation_cache = softmax(Z)   \n",
    "        \n",
    "    elif activation == \"tanh\":\n",
    "        A, activation_cache = np.tanh(Z), Z\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)  \n",
    "\n",
    "    return A, cache     # g(Z), ((A, W, b), g(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prev, W, b = dfX, parameters['W1'], parameters['b1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65140655, -0.99967261, -0.75320022, ..., -0.98027954,\n",
       "        -0.97523382, -0.92803415],\n",
       "       [ 0.96986755,  0.69808437, -0.32085339, ..., -0.26521292,\n",
       "         0.56664924,  0.38807229],\n",
       "       [-0.54699385,  0.4131557 , -0.67738797, ..., -0.70593041,\n",
       "        -0.51070505, -0.83278787],\n",
       "       ..., \n",
       "       [-0.36848702,  0.27593008,  0.25799293, ...,  0.33232859,\n",
       "        -0.19134687, -0.08094121],\n",
       "       [-0.00738913,  0.99274416,  0.19193047, ...,  0.37209484,\n",
       "         0.72252322,  0.40563738],\n",
       "       [ 0.49249233, -0.92717502, -0.0027288 , ..., -0.66265236,\n",
       "        -0.83572694, -0.70834159]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_activation_forward(A_prev, W, b, activation='tanh')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the LINEAR -> RELU -> LINEAR  TANH -> LINEAR -> SIGMOID -> LINEAR -> SOFTMAX computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "#     for l, act in zip(range(1, L), ['relu', 'tanh', 'sigmoid']):\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "#         A, cache = linear_activation_forward(A_prev, parameters['W{}'.format(l)], parameters['b{}'.format(l)], activation = act)\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W{}'.format(l)], parameters['b{}'.format(l)], activation = 'relu')\n",
    "        caches.append(cache)\n",
    "    \n",
    "    AL, cache = linear_activation_forward(A, parameters['W{}'.format(L)], parameters['b{}'.format(L)], activation = \"softmax\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (10, X.shape[1]))\n",
    "            \n",
    "    return AL, caches    # A[4], ((A[0], W1, b1, (Z1)), (A[1], W2, b2, (Z2)), (A[2], W3, b3, (Z3)), (A[3], W4, b4, (Z4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 42000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.073156  ,  0.09848152,  0.11171709, ...,  0.13684389,\n",
       "         0.1500705 ,  0.12275903],\n",
       "       [ 0.14418204,  0.0682603 ,  0.08031119, ...,  0.1552389 ,\n",
       "         0.07529559,  0.07953822],\n",
       "       [ 0.10199908,  0.11637212,  0.10497186, ...,  0.18332692,\n",
       "         0.1235681 ,  0.12304256],\n",
       "       ..., \n",
       "       [ 0.08215915,  0.07488257,  0.08623227, ...,  0.05273489,\n",
       "         0.05711142,  0.09161985],\n",
       "       [ 0.09021555,  0.07555457,  0.10281009, ...,  0.08468924,\n",
       "         0.10822773,  0.10765895],\n",
       "       [ 0.09969229,  0.10386903,  0.12451631, ...,  0.14443351,\n",
       "         0.09115748,  0.10639663]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A4, caches = L_model_forward(dfX, parameters)\n",
    "print(A4.shape)\n",
    "A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "$$ L = -\\frac{1}{m}\\Sigma_jY_jlogP_j $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function.\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability matrix, output of the forward propagation (L_model_forward())\n",
    "    Y -- ture\"label\" numpy ndarray\n",
    "    \n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    cost = -1/m * np.sum(np.sum(Y * np.log(AL), axis = 1, keepdims=True))\n",
    "    \n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3882293178060072"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = compute_cost(A4, dfY)\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backword propagation \n",
    "+ input : $da^{[l]}$ \n",
    "+ output : $da^{[l-1]}, dW^{[l]}, db^{[l]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dZ^{[l]} = da^{[l]} * g^{[l]'}(Z^{[l]}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[l]} = dZ^{[l]} * a^{[l-1]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[l]} = dZ^{[l]} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[l-1]} = W^{[l]T} \\bullet dz^{[l]}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dZ^{[l]} = W^{[l+1]T} \\bullet dZ^{[l+1]} * g^{[l]'}(Z^{[l]}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1 / m * np.dot(dZ,A_prev.T)\n",
    "    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-layer (softmax)\n",
    "+ differential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ a^{[4]}_i = P_i = \\frac{e^{Z^{[4]}_i}}{\\Sigma_i e^{Z^{[4]}_i}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[4]'}_i(Z^{[4]}_i) = \\frac{\\partial g(Z^{[4]}_i)}{\\partial Z^{[4]}_i} = P_i(1 - P_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[4]'}_j(Z^{[4]}_i) = \\frac{\\partial g(Z^{[4]}_i)}{\\partial Z^{[4]}_j} = - P_i * P_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ input\n",
    "$$ da^{[4]} = \\frac{\\partial L}{\\partial a^{[4]}_i} = P_i - y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dZ^{[4]}_i = \\frac{\\partial L}{\\partial a^{[4]}_i}\\frac{\\partial a^{[4]}_i}{\\partial Z^{[4]}_i} = (P_i - y_i){P_i(1 - P_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[3]} = W^{[4]T} \\bullet dZ^{[4]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[4]} = dZ^{[4]}_i * a^{[3]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[4]} = dZ^{[4]}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single Softmax unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    p, _ = softmax(Z)\n",
    "    dZ = dA * p * (1 - p)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-layer (sigmoid)\n",
    "+ differential\n",
    "$$ a^{[3]}_i = \\frac{1}{1 + e^{Z^{[3]}_i}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[3]'}(Z^{[3]}_i) = \\frac{\\partial g(Z^{[3]}_i)}{\\partial Z^{[3]}_i} = \\frac{1}{1 + e^{Z^{[3]}_i}}{(1 -  \\frac{1}{1 + e^{Z^{[3]}_i}})} = a^{[3]}_i(1 - a^{[3]}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ input\n",
    "$$ da^{[3]} = \\frac{\\partial L}{\\partial a^{[3]}_i} = W^{[4]T} \\bullet dZ^{[4]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dZ^{[3]}_i = \\frac{\\partial L}{\\partial a^{[3]}_i}\\frac{\\partial a^{[3]}_i}{\\partial Z^{[3]}_i} = W^{[4]T} \\bullet dZ^{[4]}_i * a^{[3]}_i(1 - a^{[3]}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[2]} = W^{[3]T} \\bullet dZ^{[3]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[3]} = dZ^{[3]}_i * a^{[2]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[3]} = dZ^{[3]}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s, _ = sigmoid(Z)\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-layer (tanh)\n",
    "+ differential\n",
    "$$ a^{[2]}_i = tanh(Z^{[2]}_i) = \\frac{1 - e^{Z^{[2]}_i}}{1 + e^{Z^{[2]}_i}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[2]'}(Z^{[2]}_i) = \\frac{\\partial a^{[2]}_i}{\\partial Z^{[2]}_i} = (1 - \\frac{1 - e^{Z^{[2]}_i}}{1 + e^{Z^{[2]}_i}})(1 + \\frac{1 - e^{Z^{[2]}_i}}{1 + e^{Z^{[2]}_i}}) = (1 - a^{[2]}_i)(1 + a^{[2]}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ input\n",
    "$$ da^{[2]} = \\frac{\\partial L}{\\partial a^{[2]}_i} = W^{[3]T} \\bullet dZ^{[3]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ output\n",
    "$$ dZ^{[2]}_i = \\frac{\\partial L}{\\partial a^{[2]}_i}\\frac{\\partial a^{[2]}_i}{\\partial Z^{[2]}_i} = W^{[3]T} \\bullet dZ^{[3]}_i * (1 - a^{[2]}_i)(1 + a^{[2]}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[1]} = W^{[2]T} \\bullet dZ^{[2]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[2]} = dZ^{[2]}_i * a^{[1]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[2]} = dZ^{[2]}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single Tanh unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    t = np.tanh(Z)\n",
    "    dZ = dA * (1 - t) * (1 + t)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-layer (relu)\n",
    "+ differential\n",
    "\n",
    "$$ a^{[1]}_i = max({0, Z^{[1]}_i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[1]'}(Z^{[1]}_i) = \\frac{\\partial a^{[1]}_i}{\\partial Z^{[1]}_i} =\\begin{cases}\n",
    "0, & \\mbox{if }Z^{[1]}_i \\le 0 \\\\\n",
    "1, & \\mbox{if }Z^{[1]}_i > 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ input\n",
    "$$ da^{[1]} = W^{[2]T} \\bullet dZ^{[2]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ output\n",
    "$$ dZ^{[1]}_i = \\frac{\\partial L}{\\partial a^{[1]}_i}\\frac{\\partial a^{[1]}_i}{\\partial Z^{[1]}_i} = \\begin{cases}\n",
    "0, & \\mbox{if }Z^{[1]}_i \\le 0 \\\\\n",
    " W^{[2]T} \\bullet dZ^{[2]}_i, & \\mbox{if }Z^{[1]}_i > 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[0]} = W^{[1]T} \\bullet dZ^{[1]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[1]} = dZ^{[1]}_i * a^{[0]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[1]} = dZ^{[1]}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\" or \"tanh\" or \"softmax\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"tanh\":\n",
    "        dZ = tanh_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        dZ = softmax_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA_prev, dW, db = linear_activation_backward(dA=A4 - dfY, cache=caches[3], activation='softmax')\n",
    "# dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR -> RELU -> LINEAR  TANH -> LINEAR -> SIGMOID -> LINEAR -> SOFTMAX group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- ture\"label\" numpy ndarray\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches)         \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = AL - dfY\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L - 1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"softmax\")\n",
    "    \n",
    "#     for l, act_func in zip(reversed(range(L-1)), ['sigmoid', 'tanh', 'relu']):\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "#         dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l + 1)], current_cache, activation = act_func)\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l + 1)], current_cache, activation = 'relu')\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = L_model_backward(A4, dfY, caches)\n",
    "# grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 \n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = update_parameters(parameters, grads, learning_rate=0.02)\n",
    "# parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(dfX, dfY, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: LINEAR -> RELU -> LINEAR  TANH -> LINEAR -> SIGMOID -> LINEAR -> SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy ndarray of shape (num_px * num_px, number of examples)\n",
    "    Y -- ture\"label\" numpy ndarray (containing 0, 1), of shape (10, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    layers_dims = layer_sizes(dfX, dfY)\n",
    "    \n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, caches = L_model_forward(dfX, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, dfY)\n",
    "        \n",
    "        grads = L_model_backward(AL, dfY, caches)\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 2.389356\n",
      "Cost after iteration 100: 2.314593\n",
      "Cost after iteration 200: 2.253378\n",
      "Cost after iteration 300: 2.195998\n",
      "Cost after iteration 400: 2.137847\n",
      "Cost after iteration 500: 2.075824\n",
      "Cost after iteration 600: 2.007432\n",
      "Cost after iteration 700: 1.930500\n",
      "Cost after iteration 800: 1.843955\n",
      "Cost after iteration 900: 1.748280\n",
      "Cost after iteration 1000: 1.646050\n",
      "Cost after iteration 1100: 1.542595\n",
      "Cost after iteration 1200: 1.450317\n",
      "Cost after iteration 1300: 1.393352\n",
      "Cost after iteration 1400: 1.437984\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ad88e5ceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = L_layer_model(dfX, dfY, learning_rate = 0.01, num_iterations = 1500, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.17640523,  0.04001572,  0.0978738 , ...,  0.05213037,\n",
       "          0.06119272, -0.13414967],\n",
       "        [ 0.04768984,  0.01484496,  0.05290452, ...,  0.00960042,\n",
       "         -0.00451133,  0.00791217],\n",
       "        [ 0.08505307, -0.08391242, -0.10117741, ..., -0.00722388,\n",
       "          0.03111244, -0.10783611],\n",
       "        ..., \n",
       "        [ 0.20717158, -0.03598082,  0.14251868, ...,  0.06307309,\n",
       "          0.0668623 , -0.08363482],\n",
       "        [-0.05782998, -0.06807925, -0.01028094, ..., -0.0820083 ,\n",
       "         -0.03597955,  0.01188161],\n",
       "        [-0.08078943, -0.06227641, -0.21208843, ..., -0.04559411,\n",
       "          0.10440344,  0.12773948]]),\n",
       " 'W2': array([[-0.05561074,  0.16656502,  0.02526298, ...,  0.0540604 ,\n",
       "         -0.03989539, -0.12331162],\n",
       "        [-0.04515199,  0.12251403, -0.19575366, ..., -0.0259569 ,\n",
       "          0.16258287,  0.0028884 ],\n",
       "        [ 0.15162653, -0.09606347, -0.04693365, ...,  0.04713492,\n",
       "         -0.14435164,  0.0500463 ],\n",
       "        ..., \n",
       "        [ 0.10885931,  0.16400169, -0.1432618 , ..., -0.01239922,\n",
       "         -0.14594951, -0.03409999],\n",
       "        [-0.01807147, -0.23439112, -0.1589087 , ...,  0.02212241,\n",
       "         -0.09819822, -0.06488312],\n",
       "        [-0.23687625, -0.01680258, -0.10872565, ..., -0.08163444,\n",
       "         -0.00425281, -0.17724282]]),\n",
       " 'W3': array([[ 0.02172263,  0.06869378,  0.00909691, ...,  0.00211189,\n",
       "         -0.04755143, -0.13265756],\n",
       "        [ 0.08569868, -0.07126135,  0.01610474, ...,  0.11021359,\n",
       "          0.04349769,  0.12139044],\n",
       "        [-0.10777561, -0.07175326,  0.01056753, ...,  0.13911072,\n",
       "          0.07998918,  0.06366829],\n",
       "        ..., \n",
       "        [ 0.03605863,  0.00953293,  0.01068805, ...,  0.01738729,\n",
       "          0.06573124,  0.07382772],\n",
       "        [-0.00696452,  0.0679671 , -0.1486248 , ..., -0.08928937,\n",
       "         -0.09244525, -0.00463551],\n",
       "        [ 0.00266718, -0.15518654,  0.00491139, ..., -0.12086849,\n",
       "          0.0330638 ,  0.14305871]]),\n",
       " 'W4': array([[  7.94436773e-02,  -1.00995720e-01,   8.86252180e-02, ...,\n",
       "           1.92375921e-01,   2.08979626e-01,  -3.11963533e-02],\n",
       "        [ -1.28932308e-02,   1.15800786e-01,  -9.47503212e-02, ...,\n",
       "          -1.31714715e-01,   1.77868749e-01,   7.77040179e-02],\n",
       "        [  1.96268323e-01,  -3.80411976e-02,  -2.34701780e-01, ...,\n",
       "           6.54540366e-02,   7.00062079e-02,   7.27088286e-02],\n",
       "        ..., \n",
       "        [ -5.64938201e-02,  -1.41906247e-04,  -1.59876316e-02, ...,\n",
       "           5.71271422e-02,  -1.46397931e-01,   1.35259899e-01],\n",
       "        [  2.50489153e-01,  -4.41389287e-02,   1.07672179e-01, ...,\n",
       "          -4.88652407e-02,  -1.88022991e-02,   7.04964942e-02],\n",
       "        [ -4.12193294e-02,   4.57239649e-02,   1.48129940e-01, ...,\n",
       "          -5.61992191e-02,   5.06181092e-03,   6.32705831e-02]]),\n",
       " 'b1': array([[ 0.00040558],\n",
       "        [ 0.00929921],\n",
       "        [-0.00140958],\n",
       "        [-0.00212878],\n",
       "        [-0.0003615 ],\n",
       "        [ 0.0138362 ],\n",
       "        [-0.00314564],\n",
       "        [-0.00166068],\n",
       "        [-0.01051055],\n",
       "        [ 0.01490054],\n",
       "        [-0.00260941],\n",
       "        [-0.00020247],\n",
       "        [ 0.02091231],\n",
       "        [ 0.00146636],\n",
       "        [ 0.01553116],\n",
       "        [ 0.01413614],\n",
       "        [ 0.02963387],\n",
       "        [ 0.00069108],\n",
       "        [ 0.01103812],\n",
       "        [ 0.01170354],\n",
       "        [ 0.00928109],\n",
       "        [-0.00642245],\n",
       "        [-0.00155146],\n",
       "        [ 0.00629621],\n",
       "        [ 0.0094363 ],\n",
       "        [ 0.0016194 ],\n",
       "        [ 0.02105517],\n",
       "        [-0.01154973],\n",
       "        [ 0.0056489 ],\n",
       "        [ 0.00344834],\n",
       "        [-0.00086902],\n",
       "        [ 0.00142353],\n",
       "        [ 0.00347061],\n",
       "        [-0.00588145],\n",
       "        [ 0.01314734],\n",
       "        [ 0.00483379],\n",
       "        [-0.00085298],\n",
       "        [ 0.00826682],\n",
       "        [ 0.01006604],\n",
       "        [ 0.02123769],\n",
       "        [-0.00290077],\n",
       "        [ 0.02166564],\n",
       "        [ 0.00613431],\n",
       "        [ 0.00568677],\n",
       "        [ 0.01366752],\n",
       "        [-0.01724168],\n",
       "        [-0.00566849],\n",
       "        [ 0.02336288],\n",
       "        [ 0.00506014],\n",
       "        [ 0.04596011],\n",
       "        [ 0.00182311],\n",
       "        [-0.0104341 ],\n",
       "        [ 0.00310278],\n",
       "        [ 0.00894366],\n",
       "        [-0.0006204 ],\n",
       "        [ 0.01299088],\n",
       "        [ 0.0139721 ],\n",
       "        [-0.00208326],\n",
       "        [ 0.01860931],\n",
       "        [ 0.03074427],\n",
       "        [ 0.01098655],\n",
       "        [ 0.001837  ],\n",
       "        [ 0.02566184],\n",
       "        [-0.00013589],\n",
       "        [ 0.00499765],\n",
       "        [ 0.01212286],\n",
       "        [ 0.01753883],\n",
       "        [ 0.02297507],\n",
       "        [-0.00028016],\n",
       "        [-0.00372372],\n",
       "        [-0.00441398],\n",
       "        [ 0.00384466],\n",
       "        [-0.00830201],\n",
       "        [-0.00303968],\n",
       "        [-0.00589762],\n",
       "        [ 0.04159797],\n",
       "        [-0.00327838],\n",
       "        [ 0.00540915],\n",
       "        [ 0.00290561],\n",
       "        [ 0.00393029],\n",
       "        [ 0.00538644],\n",
       "        [ 0.00527384],\n",
       "        [ 0.01424502],\n",
       "        [ 0.02684762],\n",
       "        [ 0.00426554],\n",
       "        [ 0.02948511],\n",
       "        [ 0.01836052],\n",
       "        [ 0.00687308],\n",
       "        [-0.00320088],\n",
       "        [ 0.00149217],\n",
       "        [ 0.00926887],\n",
       "        [ 0.00263893],\n",
       "        [-0.00164605],\n",
       "        [ 0.00239688],\n",
       "        [ 0.01396512],\n",
       "        [-0.00069971],\n",
       "        [ 0.00791008],\n",
       "        [ 0.00838944],\n",
       "        [ 0.02385639],\n",
       "        [ 0.00143215],\n",
       "        [ 0.00592016],\n",
       "        [-0.0040029 ],\n",
       "        [-0.00361573],\n",
       "        [-0.00307133],\n",
       "        [ 0.02014978],\n",
       "        [ 0.00907965],\n",
       "        [ 0.00775885],\n",
       "        [ 0.01182623],\n",
       "        [ 0.01308308],\n",
       "        [ 0.0123518 ],\n",
       "        [ 0.00268964],\n",
       "        [-0.00095123],\n",
       "        [ 0.01060847],\n",
       "        [ 0.00763163],\n",
       "        [ 0.02740455],\n",
       "        [ 0.00130441],\n",
       "        [-0.00252438],\n",
       "        [-0.00890069],\n",
       "        [-0.00315818],\n",
       "        [ 0.0167653 ],\n",
       "        [ 0.00019219],\n",
       "        [ 0.00083023],\n",
       "        [ 0.0049397 ],\n",
       "        [ 0.00025689],\n",
       "        [ 0.0198257 ],\n",
       "        [ 0.00135088],\n",
       "        [ 0.0163417 ],\n",
       "        [ 0.01009565]]),\n",
       " 'b2': array([[  4.40184116e-03],\n",
       "        [ -3.82050693e-03],\n",
       "        [  1.41721787e-02],\n",
       "        [  2.14029732e-02],\n",
       "        [ -1.70460836e-03],\n",
       "        [ -1.21116156e-03],\n",
       "        [ -3.95938228e-04],\n",
       "        [  1.10458738e-02],\n",
       "        [  2.75460563e-04],\n",
       "        [  2.29465127e-02],\n",
       "        [ -8.05155594e-03],\n",
       "        [  2.08465170e-03],\n",
       "        [  1.46550454e-05],\n",
       "        [  7.23488972e-03],\n",
       "        [  1.17297809e-03],\n",
       "        [ -3.12726966e-03],\n",
       "        [  7.02769020e-03],\n",
       "        [ -4.17199249e-03],\n",
       "        [ -3.79642563e-03],\n",
       "        [  2.35181178e-02],\n",
       "        [  1.74543276e-02],\n",
       "        [  8.73943022e-03],\n",
       "        [  8.52007178e-03],\n",
       "        [  1.36807940e-02],\n",
       "        [  8.95587870e-03],\n",
       "        [  8.75375271e-03],\n",
       "        [  1.30786815e-02],\n",
       "        [  1.15612894e-02],\n",
       "        [  1.90409928e-02],\n",
       "        [  1.07530165e-02],\n",
       "        [ -5.39057191e-03],\n",
       "        [  1.57958276e-02],\n",
       "        [  2.81194242e-03],\n",
       "        [  9.11040712e-03],\n",
       "        [  1.91129454e-05],\n",
       "        [  2.04057545e-02],\n",
       "        [  1.24835012e-02],\n",
       "        [  7.91368844e-04],\n",
       "        [  1.19203493e-02],\n",
       "        [  1.36656520e-02],\n",
       "        [ -1.69300225e-03],\n",
       "        [  6.83541947e-03],\n",
       "        [  2.64166946e-03],\n",
       "        [  3.89159529e-03],\n",
       "        [  2.08142832e-02],\n",
       "        [  9.79375398e-03],\n",
       "        [ -9.08855853e-03],\n",
       "        [ -4.95644740e-03],\n",
       "        [  2.01213946e-02],\n",
       "        [  1.05746596e-02],\n",
       "        [  1.37647388e-02],\n",
       "        [  1.12044903e-03],\n",
       "        [  2.96998652e-03],\n",
       "        [  6.73262853e-03],\n",
       "        [  4.47187820e-03],\n",
       "        [ -2.14445476e-03],\n",
       "        [  2.11716875e-02],\n",
       "        [ -3.08766579e-03],\n",
       "        [  1.58042204e-02],\n",
       "        [  1.16204730e-02],\n",
       "        [  5.26352164e-03],\n",
       "        [  2.36393460e-02],\n",
       "        [  6.35924114e-03],\n",
       "        [ -1.08625966e-02],\n",
       "        [ -4.87782679e-04],\n",
       "        [  2.09730760e-02],\n",
       "        [  2.15617826e-02],\n",
       "        [  2.27777386e-02],\n",
       "        [  1.25396638e-02],\n",
       "        [  4.08199912e-02],\n",
       "        [  8.20423253e-03],\n",
       "        [  3.63538277e-03],\n",
       "        [  1.20075341e-02],\n",
       "        [  6.68031220e-03],\n",
       "        [  1.22002330e-02],\n",
       "        [ -1.26994596e-03],\n",
       "        [ -5.46195525e-04],\n",
       "        [ -8.87805467e-03],\n",
       "        [ -9.50300607e-04],\n",
       "        [  3.84953698e-03],\n",
       "        [  4.94076169e-03],\n",
       "        [ -6.83519533e-03],\n",
       "        [  4.52218316e-03],\n",
       "        [  1.55639938e-02],\n",
       "        [ -2.85578080e-03],\n",
       "        [  1.13143882e-02],\n",
       "        [  1.49878663e-02],\n",
       "        [ -2.04134422e-03],\n",
       "        [  4.23796959e-03],\n",
       "        [  5.43561644e-03],\n",
       "        [  1.21807379e-02],\n",
       "        [  2.01792184e-03],\n",
       "        [  1.40776164e-02],\n",
       "        [  1.15704324e-03],\n",
       "        [  8.92797864e-03],\n",
       "        [ -2.12123110e-05],\n",
       "        [  4.56526959e-04],\n",
       "        [ -3.10823044e-03],\n",
       "        [  3.22932370e-02],\n",
       "        [ -1.44931625e-03],\n",
       "        [  1.24558121e-02],\n",
       "        [  6.81273300e-04],\n",
       "        [  2.59354949e-04],\n",
       "        [  1.60741806e-02],\n",
       "        [ -1.00757191e-02],\n",
       "        [ -7.21114784e-03],\n",
       "        [  4.88064257e-03],\n",
       "        [  6.87798168e-04],\n",
       "        [ -2.44384318e-03],\n",
       "        [  5.03453321e-03],\n",
       "        [  5.39197837e-03],\n",
       "        [  4.86435130e-03],\n",
       "        [  1.52581422e-02],\n",
       "        [  1.80528413e-03],\n",
       "        [  1.50669996e-02],\n",
       "        [  1.26961265e-02],\n",
       "        [  1.57049808e-02],\n",
       "        [  6.48740003e-03],\n",
       "        [  3.72897493e-04],\n",
       "        [ -9.77884282e-03],\n",
       "        [ -3.94176480e-03],\n",
       "        [  1.24033048e-02],\n",
       "        [  2.96385467e-03],\n",
       "        [  8.91468621e-04],\n",
       "        [  2.45957384e-03],\n",
       "        [  3.02307932e-03],\n",
       "        [  2.90516545e-04],\n",
       "        [ -1.77510467e-03]]),\n",
       " 'b3': array([[  4.66253979e-03],\n",
       "        [  1.10547332e-02],\n",
       "        [ -5.67874852e-03],\n",
       "        [  1.41732700e-02],\n",
       "        [  1.85164294e-02],\n",
       "        [  6.91841264e-03],\n",
       "        [ -3.11909611e-04],\n",
       "        [  5.06495336e-03],\n",
       "        [ -6.46201375e-04],\n",
       "        [ -1.18689540e-02],\n",
       "        [  6.67199534e-03],\n",
       "        [  1.05620291e-02],\n",
       "        [ -2.86037442e-03],\n",
       "        [ -2.80264871e-03],\n",
       "        [  3.28188751e-03],\n",
       "        [  1.75463306e-03],\n",
       "        [  3.22251558e-03],\n",
       "        [ -2.01923561e-03],\n",
       "        [  1.75739752e-02],\n",
       "        [  4.62457617e-03],\n",
       "        [  2.57538978e-02],\n",
       "        [  2.87799490e-02],\n",
       "        [ -6.78896417e-03],\n",
       "        [  7.23593222e-03],\n",
       "        [ -3.24909762e-03],\n",
       "        [ -2.12840588e-02],\n",
       "        [ -1.45259780e-03],\n",
       "        [  1.90886180e-02],\n",
       "        [  4.11662445e-05],\n",
       "        [ -1.50167725e-03],\n",
       "        [  1.09789075e-02],\n",
       "        [  5.45251155e-03],\n",
       "        [  3.09929830e-03],\n",
       "        [  2.29297159e-03],\n",
       "        [  2.32589659e-04],\n",
       "        [ -1.43317729e-03],\n",
       "        [  6.95875252e-03],\n",
       "        [  7.20344746e-04],\n",
       "        [  6.83917949e-03],\n",
       "        [  1.16537790e-02],\n",
       "        [  2.67932842e-03],\n",
       "        [  7.67952799e-03],\n",
       "        [ -1.33668775e-03],\n",
       "        [  1.88995469e-02],\n",
       "        [  5.77340770e-03],\n",
       "        [  5.50662399e-03],\n",
       "        [ -1.51011180e-03],\n",
       "        [ -4.94582354e-04],\n",
       "        [ -2.11387323e-03],\n",
       "        [  1.33685898e-02],\n",
       "        [  1.86221533e-02],\n",
       "        [ -1.03648104e-03],\n",
       "        [  1.20738854e-02],\n",
       "        [ -1.80336810e-03],\n",
       "        [ -5.69164505e-04],\n",
       "        [  5.16227904e-04],\n",
       "        [  2.00697691e-02],\n",
       "        [  1.18027550e-02],\n",
       "        [  7.29328967e-03],\n",
       "        [ -3.21216342e-03],\n",
       "        [  9.20995921e-05],\n",
       "        [  3.57119501e-03],\n",
       "        [ -1.44587493e-03],\n",
       "        [  3.14960267e-03],\n",
       "        [ -1.99120726e-04],\n",
       "        [ -6.81169645e-04],\n",
       "        [  5.56440306e-03],\n",
       "        [ -3.26417481e-03],\n",
       "        [ -5.60411937e-03],\n",
       "        [  1.29559240e-02],\n",
       "        [  2.75989858e-05],\n",
       "        [  4.16610678e-04],\n",
       "        [  3.32241650e-03],\n",
       "        [ -2.20536135e-03],\n",
       "        [ -2.80920466e-03],\n",
       "        [  7.27068017e-03],\n",
       "        [ -2.43718690e-03],\n",
       "        [  2.84773849e-02],\n",
       "        [ -6.00770182e-04],\n",
       "        [ -3.26089157e-03],\n",
       "        [  1.57003943e-04],\n",
       "        [ -2.03876387e-03],\n",
       "        [  3.48071333e-02],\n",
       "        [  4.85265233e-03],\n",
       "        [  2.14127571e-04],\n",
       "        [  3.20058322e-03],\n",
       "        [ -1.69889357e-03],\n",
       "        [ -3.02986802e-03],\n",
       "        [  3.75547344e-03],\n",
       "        [  3.50596376e-03],\n",
       "        [  1.08581788e-02],\n",
       "        [  7.76666515e-03],\n",
       "        [ -3.69688098e-05],\n",
       "        [  1.86695201e-02],\n",
       "        [  9.02875440e-03],\n",
       "        [  4.24093325e-03],\n",
       "        [  1.68165975e-02],\n",
       "        [  1.86592079e-02],\n",
       "        [  1.33110304e-02],\n",
       "        [ -9.13090827e-03],\n",
       "        [ -5.84465836e-03],\n",
       "        [ -7.67171719e-04],\n",
       "        [  7.19539623e-03],\n",
       "        [ -6.92467969e-03],\n",
       "        [  1.74844924e-02],\n",
       "        [  1.18086656e-02],\n",
       "        [  6.61402053e-04],\n",
       "        [  9.95087908e-03],\n",
       "        [ -6.30446536e-03],\n",
       "        [ -2.18453346e-03],\n",
       "        [ -3.63746615e-03],\n",
       "        [ -1.32236946e-02],\n",
       "        [  1.01100818e-02],\n",
       "        [  8.03968658e-03],\n",
       "        [  4.13737140e-03],\n",
       "        [  1.32482613e-02],\n",
       "        [  7.56185752e-03],\n",
       "        [  2.15392308e-03],\n",
       "        [ -1.43798102e-02],\n",
       "        [  2.74155928e-02],\n",
       "        [  6.85825743e-03],\n",
       "        [ -2.60808429e-03],\n",
       "        [  4.20704128e-04],\n",
       "        [  1.93638287e-02],\n",
       "        [ -9.67482816e-04],\n",
       "        [  7.51892326e-03],\n",
       "        [  3.30458829e-03],\n",
       "        [  1.64136816e-02]]),\n",
       " 'b4': array([[ 0.0059269 ],\n",
       "        [ 0.08827248],\n",
       "        [ 0.02480469],\n",
       "        [ 0.03976178],\n",
       "        [ 0.04137907],\n",
       "        [ 0.00882086],\n",
       "        [ 0.02803019],\n",
       "        [ 0.03887266],\n",
       "        [ 0.00765033],\n",
       "        [ 0.00899055]])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, _ = L_model_forward(df_test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27990</th>\n",
       "      <th>27991</th>\n",
       "      <th>27992</th>\n",
       "      <th>27993</th>\n",
       "      <th>27994</th>\n",
       "      <th>27995</th>\n",
       "      <th>27996</th>\n",
       "      <th>27997</th>\n",
       "      <th>27998</th>\n",
       "      <th>27999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127222</td>\n",
       "      <td>0.795582</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>9.860838e-01</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.871301</td>\n",
       "      <td>0.032114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008124</td>\n",
       "      <td>0.033227</td>\n",
       "      <td>0.035922</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.016823</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.101726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.051340</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>0.032365</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>8.211672e-07</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.114643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.252197</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>0.005761</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.738120</td>\n",
       "      <td>0.101862</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.224069</td>\n",
       "      <td>0.252956</td>\n",
       "      <td>0.061515</td>\n",
       "      <td>4.761573e-03</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>0.036291</td>\n",
       "      <td>0.089986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049621</td>\n",
       "      <td>0.321214</td>\n",
       "      <td>0.137808</td>\n",
       "      <td>0.058139</td>\n",
       "      <td>0.033716</td>\n",
       "      <td>0.057281</td>\n",
       "      <td>0.046612</td>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.018053</td>\n",
       "      <td>0.561306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025619</td>\n",
       "      <td>0.014486</td>\n",
       "      <td>0.126572</td>\n",
       "      <td>0.029872</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.026673</td>\n",
       "      <td>2.215943e-03</td>\n",
       "      <td>0.859447</td>\n",
       "      <td>0.042833</td>\n",
       "      <td>0.518086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046746</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>0.143883</td>\n",
       "      <td>0.010138</td>\n",
       "      <td>0.029737</td>\n",
       "      <td>0.060712</td>\n",
       "      <td>0.046957</td>\n",
       "      <td>0.708077</td>\n",
       "      <td>0.078136</td>\n",
       "      <td>0.066786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010059</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.225041</td>\n",
       "      <td>0.190662</td>\n",
       "      <td>0.094084</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>2.168860e-04</td>\n",
       "      <td>0.023425</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.063234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148169</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.096055</td>\n",
       "      <td>0.369509</td>\n",
       "      <td>0.088599</td>\n",
       "      <td>0.234281</td>\n",
       "      <td>0.169580</td>\n",
       "      <td>0.057915</td>\n",
       "      <td>0.187470</td>\n",
       "      <td>0.049368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>7.328601e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.067523</td>\n",
       "      <td>0.075731</td>\n",
       "      <td>0.052223</td>\n",
       "      <td>0.070557</td>\n",
       "      <td>0.087171</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>5.572475e-03</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.016456</td>\n",
       "      <td>0.083706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.520171</td>\n",
       "      <td>0.103351</td>\n",
       "      <td>0.008672</td>\n",
       "      <td>0.009327</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.005477</td>\n",
       "      <td>0.077275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.114890</td>\n",
       "      <td>0.198534</td>\n",
       "      <td>0.142711</td>\n",
       "      <td>0.529252</td>\n",
       "      <td>7.497224e-05</td>\n",
       "      <td>0.030022</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.036934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477532</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.043807</td>\n",
       "      <td>0.279602</td>\n",
       "      <td>0.584564</td>\n",
       "      <td>0.267273</td>\n",
       "      <td>0.478408</td>\n",
       "      <td>0.077928</td>\n",
       "      <td>0.076533</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.018928</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.263456</td>\n",
       "      <td>0.151174</td>\n",
       "      <td>0.088093</td>\n",
       "      <td>0.034527</td>\n",
       "      <td>7.178981e-04</td>\n",
       "      <td>0.034894</td>\n",
       "      <td>0.017205</td>\n",
       "      <td>0.043435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043949</td>\n",
       "      <td>0.066229</td>\n",
       "      <td>0.125177</td>\n",
       "      <td>0.080939</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.046559</td>\n",
       "      <td>0.041929</td>\n",
       "      <td>0.075274</td>\n",
       "      <td>0.162873</td>\n",
       "      <td>0.065352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.075311</td>\n",
       "      <td>0.103995</td>\n",
       "      <td>0.052717</td>\n",
       "      <td>0.176067</td>\n",
       "      <td>3.549069e-04</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>0.006772</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215607</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.048759</td>\n",
       "      <td>0.175799</td>\n",
       "      <td>0.208522</td>\n",
       "      <td>0.302902</td>\n",
       "      <td>0.189344</td>\n",
       "      <td>0.028566</td>\n",
       "      <td>0.466598</td>\n",
       "      <td>0.056514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5             6      \\\n",
       "0  0.127222  0.795582  0.006293  0.016792  0.005211  0.006149  9.860838e-01   \n",
       "1  0.000264  0.000056  0.051340  0.013763  0.032365  0.014147  8.211672e-07   \n",
       "2  0.738120  0.101862  0.084623  0.224069  0.252956  0.061515  4.761573e-03   \n",
       "3  0.025619  0.014486  0.126572  0.029872  0.244444  0.026673  2.215943e-03   \n",
       "4  0.010059  0.001870  0.225041  0.190662  0.094084  0.131309  2.168860e-04   \n",
       "5  0.000008  0.000006  0.000250  0.000582  0.000247  0.000060  7.328601e-07   \n",
       "6  0.067523  0.075731  0.052223  0.070557  0.087171  0.020301  5.572475e-03   \n",
       "7  0.003959  0.002750  0.114890  0.198534  0.142711  0.529252  7.497224e-05   \n",
       "8  0.018928  0.003554  0.263456  0.151174  0.088093  0.034527  7.178981e-04   \n",
       "9  0.008299  0.004103  0.075311  0.103995  0.052717  0.176067  3.549069e-04   \n",
       "\n",
       "      7         8         9        ...        27990     27991     27992  \\\n",
       "0  0.005361  0.871301  0.032114    ...     0.008124  0.033227  0.035922   \n",
       "1  0.001780  0.000046  0.114643    ...     0.002437  0.003750  0.252197   \n",
       "2  0.023450  0.036291  0.089986    ...     0.049621  0.321214  0.137808   \n",
       "3  0.859447  0.042833  0.518086    ...     0.046746  0.021120  0.143883   \n",
       "4  0.023425  0.005105  0.063234    ...     0.148169  0.021160  0.096055   \n",
       "5  0.000007  0.000009  0.001332    ...     0.000010  0.000045  0.013040   \n",
       "6  0.009601  0.016456  0.083706    ...     0.007804  0.520171  0.103351   \n",
       "7  0.030022  0.003982  0.036934    ...     0.477532  0.003153  0.043807   \n",
       "8  0.034894  0.017205  0.043435    ...     0.043949  0.066229  0.125177   \n",
       "9  0.012013  0.006772  0.016530    ...     0.215607  0.009930  0.048759   \n",
       "\n",
       "      27993     27994     27995     27996     27997     27998     27999  \n",
       "0  0.000526  0.016823  0.002201  0.007062  0.005247  0.004123  0.101726  \n",
       "1  0.016664  0.005761  0.003298  0.007122  0.018075  0.000735  0.000761  \n",
       "2  0.058139  0.033716  0.057281  0.046612  0.022991  0.018053  0.561306  \n",
       "3  0.010138  0.029737  0.060712  0.046957  0.708077  0.078136  0.066786  \n",
       "4  0.369509  0.088599  0.234281  0.169580  0.057915  0.187470  0.049368  \n",
       "5  0.000011  0.000152  0.000003  0.000234  0.000031  0.000002  0.000011  \n",
       "6  0.008672  0.009327  0.025490  0.012753  0.005897  0.005477  0.077275  \n",
       "7  0.279602  0.584564  0.267273  0.478408  0.077928  0.076533  0.020900  \n",
       "8  0.080939  0.022798  0.046559  0.041929  0.075274  0.162873  0.065352  \n",
       "9  0.175799  0.208522  0.302902  0.189344  0.028566  0.466598  0.056514  \n",
       "\n",
       "[10 rows x 28000 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.DataFrame(pd.DataFrame(test).idxmax(), columns=['Label'])\n",
    "# test.index.name='ImageId'\n",
    "# test.index += 1 \n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
