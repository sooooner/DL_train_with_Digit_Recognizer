{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [DIGIT Recognizer](https://www.kaggle.com/c/digit-recognizer)\n",
    "<img src=\"images/front_page.png\" style=\"width:350px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load & Pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "41995       0    ...            0         0         0         0         0   \n",
       "41996       0    ...            0         0         0         0         0   \n",
       "41997       0    ...            0         0         0         0         0   \n",
       "41998       0    ...            0         0         0         0         0   \n",
       "41999       0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "27995       0       0       0       0       0       0       0       0       0   \n",
       "27996       0       0       0       0       0       0       0       0       0   \n",
       "27997       0       0       0       0       0       0       0       0       0   \n",
       "27998       0       0       0       0       0       0       0       0       0   \n",
       "27999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "27995       0    ...            0         0         0         0         0   \n",
       "27996       0    ...            0         0         0         0         0   \n",
       "27997       0    ...            0         0         0         0         0   \n",
       "27998       0    ...            0         0         0         0         0   \n",
       "27999       0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "27995         0         0         0         0         0  \n",
       "27996         0         0         0         0         0  \n",
       "27997         0         0         0         0         0  \n",
       "27998         0         0         0         0         0  \n",
       "27999         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY = df_train[\"label\"]\n",
    "dfY = pd.get_dummies(dfY)\n",
    "dfY = dfY.as_matrix().reshape(len(dfY), -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = df_train.drop(\"label\", axis = 1)\n",
    "dfX /= np.max(np.max(dfX))\n",
    "dfX = dfX.as_matrix().reshape(len(dfX), -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test /= np.max(np.max(df_test))\n",
    "df_test = df_test.as_matrix().reshape(len(df_test), -1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = (dfX - np.mean(dfX)) / np.std(dfX)\n",
    "df_test = (df_test - np.mean(df_test)) / np.std(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 42000), (10, 42000), (784, 28000))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfX), np.shape(dfY), np.shape(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAHiCAYAAADxt5d3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f780200208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "for i in range(12):\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    plt.imshow(dfX[:, i].reshape(28,28))\n",
    "    plt.axis('off')\n",
    "    plt.title(np.where(dfY[:, i] == 1)[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAHVCAYAAADoyKBiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f797b28278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "for i in range(12):\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    plt.imshow(df_test[:, i].reshape(28,28))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4132 4684 4177 4351 4072 3795 4137 4401 4063 4188]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f797872198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(list(range(10)), np.sum(dfY, axis=1), palette='Greens_d')\n",
    "print(np.sum(dfY, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check None Value\n",
    "# assert(dfX.isnull().any().count() == np.shape(dfX)[1])\n",
    "# assert(dfY.isnull().any().count() == np.shape(dfY)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(dfX, dfY):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dfX -- input dataset of shape (input size, number of examples)\n",
    "    dfY -- labels of shape (output size, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    n_x -- the size of the input layer\n",
    "    n_hi -- the size of the hidden layer\n",
    "    n_y -- the size of the output layer\n",
    "    \"\"\"\n",
    "\n",
    "    n_x = dfX.shape[0]      # size of input layer\n",
    "    n_h1 = 256\n",
    "    n_h2 = 128\n",
    "    n_h3 = 128\n",
    "    n_y = dfY.shape[0]      # size of output layer\n",
    "    layer_dims = (n_x, n_h1, n_h2, n_h3, n_y)\n",
    "    \n",
    "    return layer_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 256, 128, 128, 10)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dims = layer_sizes(dfX, dfY)\n",
    "layer_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    layer_dims -- output of layer_sizes()\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h1, n_x)\n",
    "                    b1 -- bias vector of shape (n_h1, 1)\n",
    "                    W2 -- weight matrix of shape (n_h2, n_h1)\n",
    "                    b2 -- bias vector of shape (n_h2, 1)\n",
    "                    W3 -- weight matrix of shape (n_y, n_h2)\n",
    "                    b3 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)   \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.1\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_parameters(layer_dims)\n",
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape W1 : (256, 784)\n",
      "shape b1 : (256, 1)\n",
      "shape W2 : (128, 256)\n",
      "shape b2 : (128, 1)\n",
      "shape W3 : (128, 128)\n",
      "shape b3 : (128, 1)\n",
      "shape W4 : (10, 128)\n",
      "shape b4 : (10, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in parameters.keys():\n",
    "    print(\"shape {} :\".format(i), np.shape(parameters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 42000)\n",
      "Z = [[-0.77773815 -4.35866678 -0.98031035 ..., -2.30466824 -2.18948154\n",
      "  -1.64403224]\n",
      " [ 2.09005949  0.86355422 -0.33259814 ..., -0.27170747  0.64257345\n",
      "   0.40952854]\n",
      " [-0.61408159  0.43941051 -0.82427132 ..., -0.87902476 -0.56368313\n",
      "  -1.19716513]\n",
      " ..., \n",
      " [-1.09383622  0.48491366 -0.55589661 ..., -0.32952898 -1.63280494\n",
      "  -1.17637186]\n",
      " [-0.40874809 -2.56619376  0.11131967 ..., -1.3034728   0.45366759\n",
      "  -0.86199782]\n",
      " [ 1.05330363 -1.01222882  0.84780927 ...,  0.25236444  0.63664942\n",
      "   0.40705933]]\n"
     ]
    }
   ],
   "source": [
    "A, W, b = dfX, parameters['W1'], parameters['b1']\n",
    "Z, linear_cache = linear_forward(A, W, b)\n",
    "print(Z.shape)\n",
    "print(\"Z = \" + str(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31480757,  0.01263378,  0.27283021, ...,  0.09073708,\n",
       "         0.10069904,  0.16191714],\n",
       "       [ 0.88993325,  0.7034027 ,  0.41760859, ...,  0.43248796,\n",
       "         0.65533496,  0.60097483],\n",
       "       [ 0.35112869,  0.60811856,  0.30485773, ...,  0.29337991,\n",
       "         0.36269568,  0.23197991],\n",
       "       ..., \n",
       "       [ 0.25089658,  0.61890749,  0.36449743, ...,  0.41835523,\n",
       "         0.16344647,  0.23570517],\n",
       "       [ 0.39921234,  0.07134608,  0.52780121, ...,  0.21358113,\n",
       "         0.61151088,  0.29692211],\n",
       "       [ 0.74140878,  0.26654389,  0.70010739, ...,  0.56275838,\n",
       "         0.65399567,  0.60038255]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(Z)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU activation in numpy.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.09005949,  0.86355422,  0.        , ...,  0.        ,\n",
       "         0.64257345,  0.40952854],\n",
       "       [ 0.        ,  0.43941051,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.48491366,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.11131967, ...,  0.        ,\n",
       "         0.45366759,  0.        ],\n",
       "       [ 1.05330363,  0.        ,  0.84780927, ...,  0.25236444,\n",
       "         0.63664942,  0.40705933]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(Z)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Implement the softmax activation in numpy.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.31577917e-03,   2.11394546e-05,   1.08989609e-03, ...,\n",
       "          2.02856594e-04,   2.91567909e-04,   5.62427107e-04],\n",
       "       [  2.31553686e-02,   3.91810022e-03,   2.08296961e-03, ...,\n",
       "          1.54914751e-03,   4.95091620e-03,   4.38446248e-03],\n",
       "       [  1.54973752e-03,   2.56372990e-03,   1.27394884e-03, ...,\n",
       "          8.43991803e-04,   1.48188669e-03,   8.79302211e-04],\n",
       "       ..., \n",
       "       [  9.59187165e-04,   2.68308256e-03,   1.66611755e-03, ...,\n",
       "          1.46211392e-03,   5.08746339e-04,   8.97777193e-04],\n",
       "       [  1.90297619e-03,   1.26927264e-04,   3.24693795e-03, ...,\n",
       "          5.52080980e-04,   4.09868746e-03,   1.22941775e-03],\n",
       "       [  8.21096778e-03,   6.00389818e-04,   6.78152488e-03, ...,\n",
       "          2.61634079e-03,   4.92167353e-03,   4.37364970e-03]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(Z)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\" or \"tanh\" or \"softmax\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)  \n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        A, activation_cache = softmax(Z)   \n",
    "        \n",
    "    elif activation == \"tanh\":\n",
    "        A, activation_cache = np.tanh(Z), Z\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)  \n",
    "\n",
    "    return A, cache     # g(Z), ((A, W, b), g(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prev, W, b = dfX, parameters['W1'], parameters['b1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65140655, -0.99967261, -0.75320022, ..., -0.98027954,\n",
       "        -0.97523382, -0.92803415],\n",
       "       [ 0.96986755,  0.69808437, -0.32085339, ..., -0.26521292,\n",
       "         0.56664924,  0.38807229],\n",
       "       [-0.54699385,  0.4131557 , -0.67738797, ..., -0.70593041,\n",
       "        -0.51070505, -0.83278787],\n",
       "       ..., \n",
       "       [-0.79827403,  0.45017016, -0.50492655, ..., -0.31809748,\n",
       "        -0.92646   , -0.82630413],\n",
       "       [-0.38740918, -0.98826437,  0.11086211, ..., -0.8626145 ,\n",
       "         0.4249091 , -0.69728557],\n",
       "       [ 0.78308743, -0.7666823 ,  0.68992325, ...,  0.24713998,\n",
       "         0.56261386,  0.38597294]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_activation_forward(A_prev, W, b, activation='tanh')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the LINEAR -> RELU -> LINEAR  TANH -> LINEAR -> SIGMOID -> LINEAR -> SOFTMAX computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "#     for l, act in zip(range(1, L), ['relu', 'tanh', 'sigmoid']):\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "#         A, cache = linear_activation_forward(A_prev, parameters['W{}'.format(l)], parameters['b{}'.format(l)], activation = act)\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W{}'.format(l)], parameters['b{}'.format(l)], activation = 'relu')\n",
    "        caches.append(cache)\n",
    "    \n",
    "    AL, cache = linear_activation_forward(A, parameters['W{}'.format(L)], parameters['b{}'.format(L)], activation = \"softmax\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (10, X.shape[1]))\n",
    "            \n",
    "    return AL, caches    # A[4], ((A[0], W1, b1, (Z1)), (A[1], W2, b2, (Z2)), (A[2], W3, b3, (Z3)), (A[3], W4, b4, (Z4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 42000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.15947807,  0.42593811,  0.13137724, ...,  0.09646508,\n",
       "         0.25295374,  0.09117925],\n",
       "       [ 0.17773794,  0.10411621,  0.21923921, ...,  0.28373169,\n",
       "         0.14169276,  0.14572942],\n",
       "       [ 0.16556886,  0.05250996,  0.10871867, ...,  0.09389576,\n",
       "         0.05535855,  0.11806757],\n",
       "       ..., \n",
       "       [ 0.1218831 ,  0.2071502 ,  0.16728853, ...,  0.18983825,\n",
       "         0.17259848,  0.19701596],\n",
       "       [ 0.04212411,  0.01016343,  0.03120057, ...,  0.01547168,\n",
       "         0.04635204,  0.06052308],\n",
       "       [ 0.13177386,  0.06774398,  0.15026938, ...,  0.10711403,\n",
       "         0.15695012,  0.15843846]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A4, caches = L_model_forward(dfX, parameters)\n",
    "print(A4.shape)\n",
    "A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ L(\\hat{y},y) = -\\frac{1}{m}\\Sigma_jY_jlog\\hat{y}_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ J = \\frac{1}{m}\\Sigma_{i=1}^mL(\\hat{y^{(i)}},y^{(i)}) + \\frac{\\lambda}{2m}\\Sigma_{l=1}^L\\|W^{[l]}\\|^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y, caches, Lambd=1):\n",
    "    \"\"\"\n",
    "    Implement the cost function.\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability matrix, output of the forward propagation (L_model_forward())\n",
    "    Y -- ture\"label\" numpy ndarray\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "    Lambd -- regularization parameter\n",
    "    \n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    w_norm = np.sum([np.sum(caches[i][0][1]**2) for i in range(len(caches))])\n",
    "    cost = -1/m * np.sum(np.sum(Y * np.log(AL), axis = 1, keepdims=True)) + (Lambd * w_norm) / (2*m)\n",
    "    \n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4928627404963524"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = compute_cost(A4, dfY, caches, Lambd=1)\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backword propagation \n",
    "+ input : $da^{[l]}$ \n",
    "+ output : $da^{[l-1]}, dW^{[l]}, db^{[l]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dZ^{[l]} = da^{[l]} * g^{[l]'}(Z^{[l]}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[l]} = dZ^{[l]} * a^{[l-1]} + \\frac{\\lambda}{m}W^{[l]} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[l]} = dZ^{[l]} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[l-1]} = W^{[l]T} \\bullet dz^{[l]}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dZ^{[l]} = W^{[l+1]T} \\bullet dZ^{[l+1]} * g^{[l]'}(Z^{[l]}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache, Lambd=1):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "    Lambd -- regularization parameter\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1 / m * np.dot(dZ,A_prev.T) + Lambd * W /m\n",
    "    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-layer (softmax)\n",
    "+ differential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ a^{[4]}_i = P_i = \\frac{e^{Z^{[4]}_i}}{\\Sigma_i e^{Z^{[4]}_i}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[4]'}_i(Z^{[4]}_i) = \\frac{\\partial g(Z^{[4]}_i)}{\\partial Z^{[4]}_i} = P_i(1 - P_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[4]'}_j(Z^{[4]}_i) = \\frac{\\partial g(Z^{[4]}_i)}{\\partial Z^{[4]}_j} = - P_i * P_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ input\n",
    "$$ da^{[4]} = \\frac{\\partial L}{\\partial a^{[4]}_i} = P_i - y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dZ^{[4]}_i = \\frac{\\partial L}{\\partial a^{[4]}_i}\\frac{\\partial a^{[4]}_i}{\\partial Z^{[4]}_i} = (P_i - y_i){P_i(1 - P_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[3]} = W^{[4]T} \\bullet dZ^{[4]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[4]} = dZ^{[4]}_i * a^{[3]} + \\frac{\\lambda}{m}W^{[4]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[4]} = dZ^{[4]}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single Softmax unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    p, _ = softmax(Z)\n",
    "    dZ = dA * p * (1 - p)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-layer (sigmoid)\n",
    "+ differential\n",
    "$$ a^{[3]}_i = \\frac{1}{1 + e^{Z^{[3]}_i}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[3]'}(Z^{[3]}_i) = \\frac{\\partial g(Z^{[3]}_i)}{\\partial Z^{[3]}_i} = \\frac{1}{1 + e^{Z^{[3]}_i}}{(1 -  \\frac{1}{1 + e^{Z^{[3]}_i}})} = a^{[3]}_i(1 - a^{[3]}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ input\n",
    "$$ da^{[3]} = \\frac{\\partial L}{\\partial a^{[3]}_i} = W^{[4]T} \\bullet dZ^{[4]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dZ^{[3]}_i = \\frac{\\partial L}{\\partial a^{[3]}_i}\\frac{\\partial a^{[3]}_i}{\\partial Z^{[3]}_i} = W^{[4]T} \\bullet dZ^{[4]}_i * a^{[3]}_i(1 - a^{[3]}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[2]} = W^{[3]T} \\bullet dZ^{[3]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[3]} = dZ^{[3]}_i * a^{[2]} + \\frac{\\lambda}{m}W^{[3]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[3]} = dZ^{[3]}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s, _ = sigmoid(Z)\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-layer (tanh)\n",
    "+ differential\n",
    "$$ a^{[2]}_i = tanh(Z^{[2]}_i) = \\frac{1 - e^{Z^{[2]}_i}}{1 + e^{Z^{[2]}_i}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[2]'}(Z^{[2]}_i) = \\frac{\\partial a^{[2]}_i}{\\partial Z^{[2]}_i} = (1 - \\frac{1 - e^{Z^{[2]}_i}}{1 + e^{Z^{[2]}_i}})(1 + \\frac{1 - e^{Z^{[2]}_i}}{1 + e^{Z^{[2]}_i}}) = (1 - a^{[2]}_i)(1 + a^{[2]}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ input\n",
    "$$ da^{[2]} = \\frac{\\partial L}{\\partial a^{[2]}_i} = W^{[3]T} \\bullet dZ^{[3]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ output\n",
    "$$ dZ^{[2]}_i = \\frac{\\partial L}{\\partial a^{[2]}_i}\\frac{\\partial a^{[2]}_i}{\\partial Z^{[2]}_i} = W^{[3]T} \\bullet dZ^{[3]}_i * (1 - a^{[2]}_i)(1 + a^{[2]}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[1]} = W^{[2]T} \\bullet dZ^{[2]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[2]} = dZ^{[2]}_i * a^{[1]} + \\frac{\\lambda}{m}W^{[2]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[2]} = dZ^{[2]}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single Tanh unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    t = np.tanh(Z)\n",
    "    dZ = dA * (1 - t) * (1 + t)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-layer (relu)\n",
    "+ differential\n",
    "\n",
    "$$ a^{[1]}_i = max({0, Z^{[1]}_i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g^{[1]'}(Z^{[1]}_i) = \\frac{\\partial a^{[1]}_i}{\\partial Z^{[1]}_i} =\\begin{cases}\n",
    "0, & \\mbox{if }Z^{[1]}_i \\le 0 \\\\\n",
    "1, & \\mbox{if }Z^{[1]}_i > 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ input\n",
    "$$ da^{[1]} = W^{[2]T} \\bullet dZ^{[2]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ output\n",
    "$$ dZ^{[1]}_i = \\frac{\\partial L}{\\partial a^{[1]}_i}\\frac{\\partial a^{[1]}_i}{\\partial Z^{[1]}_i} = \\begin{cases}\n",
    "0, & \\mbox{if }Z^{[1]}_i \\le 0 \\\\\n",
    " W^{[2]T} \\bullet dZ^{[2]}_i, & \\mbox{if }Z^{[1]}_i > 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ da^{[0]} = W^{[1]T} \\bullet dZ^{[1]}_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ dW^{[1]} = dZ^{[1]}_i * a^{[0]} + \\frac{\\lambda}{m}W^{[1]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ db^{[1]} = dZ^{[1]}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation, Lambd=1):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\" or \"tanh\" or \"softmax\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache, Lambd)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache, Lambd)\n",
    "        \n",
    "    elif activation == \"tanh\":\n",
    "        dZ = tanh_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache, Lambd)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        dZ = softmax_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache, Lambd)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA_prev, dW, db = linear_activation_backward(dA=A4 - dfY, cache=caches[3], activation='softmax')\n",
    "# dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches, Lambd=1):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR -> RELU -> LINEAR  TANH -> LINEAR -> SIGMOID -> LINEAR -> SOFTMAX group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- ture\"label\" numpy ndarray\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches)         \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = AL - dfY\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L - 1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"softmax\", Lambd=Lambd)\n",
    "    \n",
    "#     for l, act_func in zip(reversed(range(L-1)), ['sigmoid', 'tanh', 'relu']):\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "#         dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l + 1)], current_cache, activation = act_func)\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l + 1)], current_cache, activation = 'relu', Lambd=Lambd)\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = L_model_backward(A4, dfY, caches)\n",
    "# grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 \n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = update_parameters(parameters, grads, learning_rate=0.02)\n",
    "# parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(dfX, dfY, learning_rate = 0.0075, num_iterations = 3000, print_cost=False, Lambd=1):\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: LINEAR -> RELU -> LINEAR  TANH -> LINEAR -> SIGMOID -> LINEAR -> SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy ndarray of shape (num_px * num_px, number of examples)\n",
    "    Y -- ture\"label\" numpy ndarray (containing 0, 1), of shape (10, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    layers_dims = layer_sizes(dfX, dfY)\n",
    "    \n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, caches = L_model_forward(dfX, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, dfY, caches, Lambd=Lambd)\n",
    "        \n",
    "        grads = L_model_backward(AL, dfY, caches, Lambd=Lambd)\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 2.492863\n",
      "Cost after iteration 100: 2.240551\n",
      "Cost after iteration 200: 2.097509\n",
      "Cost after iteration 300: 1.972237\n",
      "Cost after iteration 400: 1.851318\n",
      "Cost after iteration 500: 1.730880\n",
      "Cost after iteration 600: 1.611545\n",
      "Cost after iteration 700: 1.503163\n",
      "Cost after iteration 800: 1.422909\n",
      "Cost after iteration 900: 1.407305\n",
      "Cost after iteration 1000: 1.479776\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7977d6160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = L_layer_model(dfX, dfY, learning_rate = 0.01, num_iterations = 1001, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test, _ = L_model_forward(df_test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label\n",
       "27996      7\n",
       "27997      7\n",
       "27998      3\n",
       "27999      9\n",
       "28000      2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = pd.DataFrame(pd.DataFrame(test).idxmax(), columns=['Label'])\n",
    "# test.index.name='ImageId'\n",
    "# test.index += 1 \n",
    "# test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê°œì„ ì‚¬í•­ \n",
    "+ ~~Regularization~~\n",
    "+ ~~Normalizing inputs~~\n",
    "+ Vanishing/exploding gradients\n",
    "+ Mini-batch\n",
    "+ Dropout vs Batch Normalizing\n",
    "+ Adam optimization\n",
    "+ Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
